{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step, import libraries and then dataset\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and encode the date\n",
    "df = pd.read_csv(\"../input/coinbaseUSD_1-min_data.csv\")\n",
    "df['date'] = pd.to_datetime(df['Timestamp'],unit='s').dt.date\n",
    "group = df.groupby('date')\n",
    "Real_Price = group['Weighted_Price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bitcoin predictions are going to be for a month and so we need to split the dataset accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "prediction_days = 30\n",
    "df_train= Real_Price[:len(Real_Price)-prediction_days]\n",
    "df_test= Real_Price[len(Real_Price)-prediction_days:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some pre-processing is also necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocess\n",
    "training_set = df_train.values\n",
    "training_set = np.reshape(training_set, (len(training_set), 1))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "training_set = sc.fit_transform(training_set)\n",
    "X_train = training_set[0:len(training_set)-1]\n",
    "y_train = training_set[1:len(training_set)]\n",
    "X_train = np.reshape(X_train, (len(X_train), 1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now keras to build the rNN, Long short-term memory!!! (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "regressor.add(LSTM(units = 4, activation = 'sigmoid', input_shape = (None, 1)))\n",
    "\n",
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, batch_size = 5, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why RNN COULD \"fail\". WE used values of today to predict the future values. We need to think about what are we \"feeding\" our RNN with. Because it can happen that RNN will only learn that price will be slightly higher than yesterdays price. Which is true, except when it is not. Then it fails big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the predictions\n",
    "test_set = df_test.values\n",
    "inputs = np.reshape(test_set, (len(test_set), 1))\n",
    "inputs = sc.transform(inputs)\n",
    "inputs = np.reshape(inputs, (len(inputs), 1, 1))\n",
    "predicted_BTC_price = regressor.predict(inputs)\n",
    "predicted_BTC_price = sc.inverse_transform(predicted_BTC_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the results\n",
    "plt.figure(figsize=(25,15), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = plt.gca()  \n",
    "plt.plot(test_set, color = 'red', label = 'Real BTC Price')\n",
    "plt.plot(predicted_BTC_price, color = 'blue', label = 'Predicted BTC Price')\n",
    "plt.title('BTC Price Prediction', fontsize=40)\n",
    "df_test = df_test.reset_index()\n",
    "x=df_test.index\n",
    "labels = df_test['date']\n",
    "plt.xticks(x, labels, rotation = 'vertical')\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(18)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(18)\n",
    "plt.xlabel('Time', fontsize=40)\n",
    "plt.ylabel('BTC Price(USD)', fontsize=40)\n",
    "plt.legend(loc=2, prop={'size': 25})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA Let us first go through theoretical part of ARIMA.\n",
    "\n",
    "An ARIMA model is a class of statistical models for analyzing and forecasting time series data. ARIMA model is one model for non-stationarity. It assumes that the data becomes stationary after differencing.\n",
    "\n",
    "ARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a generalization of the simpler AutoRegressive Moving Average and adds the notion of integration.\n",
    "\n",
    "These acronyms describe it pretty well:\n",
    "\n",
    "AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations. 2.I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
    "MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
    "Each of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.\n",
    "\n",
    "Parameters are defined as follows:\n",
    "\n",
    "p: The number of lag observations included in the model, also called the lag order.\n",
    "d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "q: The size of the moving average window, also called the order of moving average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adopting an ARIMA model for a time series assumes that the underlying process that generated the observations is an ARIMA process. This may seem obvious, but helps to motivate the need to confirm the assumptions of the model in the raw observations and in the residual errors of forecasts from the model.\n",
    "\n",
    "But how do we check that? And how to de determine the parameters p,d,q in the model? First of all we need to make sure that the time-series is stationary, thats where differencing comes into place (degree corrects the level of non-stationarity if possible) And model parameters can be determined with the Box-Jenkins Method.\n",
    "\n",
    "Basicaly we have the following situation:\n",
    "\n",
    "Define the model by calling ARIMA() and passing in the p, d, and q parameters.\n",
    "The model is prepared on the training data by calling the fit() function.\n",
    "Predictions can be made by calling the predict() function and specifying the index of the time or times to be predicted.\n",
    "How does Box-Jenkins Method work? https://machinelearningmastery.com/gentle-introduction-box-jenkins-method-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../input/coinbaseUSD_1-min_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform our index into time data and then split the time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unix-time to \n",
    "df.Timestamp = pd.to_datetime(df.Timestamp, unit='s')\n",
    "\n",
    "# Resampling to daily frequency\n",
    "df.index = df.Timestamp\n",
    "df = df.resample('D').mean()\n",
    "\n",
    "# Resampling to monthly frequency\n",
    "df_month = df.resample('M').mean()\n",
    "\n",
    "# Resampling to annual frequency\n",
    "df_year = df.resample('A-DEC').mean()\n",
    "\n",
    "# Resampling to quarterly frequency\n",
    "df_Q = df.resample('Q-DEC').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS\n",
    "fig = plt.figure(figsize=[15, 7])\n",
    "plt.suptitle('Bitcoin exchanges, mean USD', fontsize=22)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(df.Weighted_Price, '-', label='By Days')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(df_month.Weighted_Price, '-', label='By Months')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(df_Q.Weighted_Price, '-', label='By Quarters')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(df_year.Weighted_Price, '-', label='By Years')\n",
    "plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationarity check and STL-decomposition of the series* Lower the p value the better. Stationarity is our models main assumption and dickey fuller is just hypothesis test of the unit root test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,7])\n",
    "sm.tsa.seasonal_decompose(df_month.Weighted_Price).plot()\n",
    "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.Weighted_Price)[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Obviously not stationary, hence we ought transform our data. First Box-cox transformation then check the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox Transformations\n",
    "df_month['Weighted_Price_box'], lmbda = stats.boxcox(df_month.Weighted_Price)\n",
    "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.Weighted_Price)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need another transformation. Seasonal differentiation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal differentiation\n",
    "df_month['prices_box_diff'] = df_month.Weighted_Price_box - df_month.Weighted_Price_box.shift(12)\n",
    "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.prices_box_diff[12:])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Again series is not stationary, finally let us try regular differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular differentiation\n",
    "df_month['prices_box_diff2'] = df_month.prices_box_diff - df_month.prices_box_diff.shift(1)\n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "# STL-decomposition\n",
    "sm.tsa.seasonal_decompose(df_month.prices_box_diff2[13:]).plot()   \n",
    "print(\"Dickey–Fuller test: p=%f\" % sm.tsa.stattools.adfuller(df_month.prices_box_diff2[13:])[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to make model selection, with help of :\n",
    "\n",
    "Autocorrelation Function (ACF). The plot summarizes the correlation of an observation with lag values. The x-axis shows the lag and the y-axis shows the correlation coefficient between -1 and 1 for negative and positive correlation.\n",
    "Partial Autocorrelation Function (PACF). The plot summarizes the correlations for an observation with lag values that is not accounted for by prior lagged observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial approximation of parameters\n",
    "Qs = range(0, 2)\n",
    "qs = range(0, 3)\n",
    "Ps = range(0, 3)\n",
    "ps = range(0, 3)\n",
    "D=1\n",
    "d=1\n",
    "parameters = product(ps, qs, Ps, Qs)\n",
    "parameters_list = list(parameters)\n",
    "len(parameters_list)\n",
    "\n",
    "# Model Selection\n",
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "warnings.filterwarnings('ignore')\n",
    "for param in parameters_list:\n",
    "    try:\n",
    "        model=sm.tsa.statespace.SARIMAX(df_month.Weighted_Price_box, order=(param[0], d, param[1]), \n",
    "                                        seasonal_order=(param[2], D, param[3], 12)).fit(disp=-1)\n",
    "    except ValueError:\n",
    "        print('wrong parameters:', param)\n",
    "        continue\n",
    "    aic = model.aic\n",
    "    if aic < best_aic:\n",
    "        best_model = model\n",
    "        best_aic = aic\n",
    "        best_param = param\n",
    "    results.append([param, model.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Models\n",
    "result_table = pd.DataFrame(results)\n",
    "result_table.columns = ['parameters', 'aic']\n",
    "print(result_table.sort_values(by = 'aic', ascending=True).head())\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Good, now we can make predictions with our (ARIMA) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Box-Cox Transformation Function\n",
    "def invboxcox(y,lmbda):\n",
    "   if lmbda == 0:\n",
    "      return(np.exp(y))\n",
    "   else:\n",
    "      return(np.exp(np.log(lmbda*y+1)/lmbda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "df_month2 = df_month[['Weighted_Price']]\n",
    "date_list = [datetime(2017, 6, 30), datetime(2017, 7, 31), datetime(2017, 8, 31), datetime(2017, 9, 30), \n",
    "             datetime(2017, 10, 31), datetime(2017, 11, 30), datetime(2017, 12, 31), datetime(2018, 1, 31),\n",
    "             datetime(2018, 1, 28)]\n",
    "future = pd.DataFrame(index=date_list, columns= df_month.columns)\n",
    "df_month2 = pd.concat([df_month2, future])\n",
    "df_month2['forecast'] = invboxcox(best_model.predict(start=0, end=75), lmbda)\n",
    "plt.figure(figsize=(15,7))\n",
    "df_month2.Weighted_Price.plot()\n",
    "df_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\n",
    "plt.legend()\n",
    "plt.title('Bitcoin exchanges, by months')\n",
    "plt.ylabel('mean USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
